{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-08T20:39:42.290372Z",
     "start_time": "2024-06-08T20:39:42.279203Z"
    }
   },
   "source": [
    "# Install necessary libraries\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install groq"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:18:48.373124Z",
     "start_time": "2024-06-08T21:18:48.358268Z"
    }
   },
   "cell_type": "code",
   "source": "GROQ_API_KEY = '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'",
   "id": "3b8376df851b39a5",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T20:45:10.913656Z",
     "start_time": "2024-06-08T20:45:10.908811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ['GROQ_API_KEY'] = GROQ_API_KEY"
   ],
   "id": "f572448f8a65800c",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T20:45:14.521950Z",
     "start_time": "2024-06-08T20:45:13.728995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ],
   "id": "e8bcf2f66d47053a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models, also known as large language models or transformer-based models, have gained significant attention in recent years due to their widespread adoption in various applications. Here are some reasons why fast language models are important:\n",
      "\n",
      "1. **Speed and Efficiency**: Fast language models are designed to process and generate text quickly, making them suitable for real-time applications, such as chatbots, language translation, and language learning systems.\n",
      "2. **Scalability**: As the size of the training dataset grows, traditional language models may become computationally expensive and slow. Fast language models are optimized to handle large datasets and perform well on edge devices, making them ideal for real-time processing.\n",
      "3. **Interactivity**: Fast language models enable interactive applications, such as conversational UIs, voice assistants, and messaging platforms. They can respond quickly to user inputs, providing a seamless and engaging experience.\n",
      "4. **Real-time processing**: Fast language models can process and respond to user inputs in a fraction of a second, making them suitable for applications that require rapid processing, such as language translation, speech recognition, and text summarization.\n",
      "5. **Improved model accuracy**: Fast language models often rely on more advanced architectures, such as transformer-based models, which have been shown to achieve state-of-the-art results in various NLP tasks.\n",
      "6. **Edge and Cloud computing**: Fast language models enable the widespread adoption of edge computing and cloud computing, as they can be deployed on resource-constrained devices, such as smartphones and IoT devices, while still providing high-quality language processing capabilities.\n",
      "7. **Conversational AI**: Fast language models are essential for conversational AI applications, such as chatbots, virtual assistants, and language translation robots. They can respond quickly and accurately to user inputs, enabling more natural and engaging human-computer interactions.\n",
      "8. **Embracing Big Data**: Fast language models can efficiently process large amounts of data, enabling the analysis and insights needed for various applications, such as text analysis, sentiment analysis, and topic modeling.\n",
      "9. **Language understanding**: Fast language models can understand the nuances of human language, including idioms, colloquialisms, and context-dependent meanings, which is crucial for applications like natural language understanding and language translation.\n",
      "10. **Increased accessibility**: Fast language models can be used to create accessible natural language interfaces for people with disabilities, enabling equal access to information and services.\n",
      "\n",
      "In summary, fast language models have revolutionized the NLP landscape by enabling efficient, accurate, and real-time language processing capabilities. Their wide adoption has opened up new opportunities in various industries, from healthcare and education to customer service and entertainment.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3900227524395ab4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
